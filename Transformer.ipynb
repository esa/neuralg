{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb925dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Needed for training and evaluation\n",
    "from losses import *\n",
    "from RandomMatrixDataSet import get_sample,RandomMatrixDataSet,SingularvalueMatrix, EigenMatrix\n",
    "from train import train_on_batch, run_training\n",
    "from evaluation import *\n",
    "from plotting import plot_loss_logs, error_histogram, plot_mean_identity_approx\n",
    "\n",
    "#Seed and looks\n",
    "torch.random.seed = 1234\n",
    "plt.rcParams['figure.figsize'] = [14, 6]\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bed27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        #This is what I added in terms of decoder \n",
    "        decoder_layers = TransformerDecoderLayer(d_model,nhead)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers,nhead)\n",
    "        \n",
    "        #This used to be nn.Embedding\n",
    "        self.embedding = MatrixEmbedding(d_model) \n",
    "        \n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.generator = nn.Linear(d_model, ntoken) \n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        #self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        #self.generator.bias.data.zero_()\n",
    "        #self.generator.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor,tgt: Tensor, tgt_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src_embedded = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        encoded_src = self.transformer_encoder(self.pos_encoder(src_embedded), src_mask)\n",
    "        #Added this for the decoder  \n",
    "        tgt_embedded = self.embedding(tgt)*math.sqrt(self.d_model) #\n",
    "        output = self.transformer_decoder(self.pos_encoder(tgt_embedded),encoded_src,src_mask,tgt_mask)\n",
    "        \n",
    "        return self.generator(encoded_src) #This is without the decoder\n",
    "        #return self.generator(output) This is with decoder\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class MatrixEmbedding(nn.Module):\n",
    "    \"\"\" \"\"\"\n",
    "    def __init__(self,d_model: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        #Maybe add a e.g. trainable linear embedding? \n",
    "        self.linear = nn.Linear(d_model,d_model)\n",
    "        \n",
    "    def forward(self, x: Tensor):\n",
    "        x = x[:,:,None]\n",
    "        m = torch.arange(x.shape[0]) \n",
    "        return torch.cat((x,m[:,None,None]), 2) #embed with index. Only works with d_model = 2\n",
    "        #return torch.cat(self.d_model*[x], 2) #Just stack the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94130e",
   "metadata": {},
   "source": [
    "### Here I generate a src-tgt pair to validate the pipe-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0824ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1 \n",
    "matrix_dimension = 3\n",
    "matrix_parameters = {\"N\": N,\n",
    "                    \"d\": matrix_dimension}\n",
    "# Need to generate matrix data. These are just random matrices \n",
    "def get_batch(matrix_parameters):\n",
    "    M = get_sample(matrix_parameters)\n",
    "    M.compute_labels()\n",
    "    data = torch.permute(torch.flatten(M.X, start_dim = 1),(1,0))\n",
    "    target = torch.permute(torch.flatten(M.Y, start_dim = 1),(1,0))\n",
    "    return data, target\n",
    "                         \n",
    "d,t = get_batch(matrix_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edae233",
   "metadata": {},
   "source": [
    "## Initiate an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = 1 #size of \"vocabulary\"\n",
    "emsize = 2  # embedding dimension - currently just adding index in sequence \n",
    "d_hid = 32  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)#.to(device)\n",
    "#Some normalization found from another source\n",
    "#for p in model.parameters():\n",
    "#    if p.dim() > 1:\n",
    "#        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "#Data parameters (Not using at the moment)\n",
    "matrix_dimension = 3\n",
    "batch_size = 10\n",
    "matrix_parameters = {\"N\":batch_size,\n",
    "                  \"d\": matrix_dimension}\n",
    "\n",
    "\n",
    "#I am not entirely sure about the masks\n",
    "src_mask = generate_square_subsequent_mask(matrix_dimension**2) #A fixed matrix size to begin with\n",
    "tgt_mask = generate_square_subsequent_mask(matrix_dimension**2) # -||- \n",
    "\n",
    "#Training parameters\n",
    "k = 10000\n",
    "\n",
    "#criterion = nn.MSELoss()\n",
    "\n",
    "#This is the loss Ive used in previous training\n",
    "def relative_inv_MSE(predicted,x):\n",
    "    #Normalize with batch square mean?\n",
    "    id = torch.eye(x.shape[1])\n",
    "    id_approx = torch.matmul(predicted,x)\n",
    "    return((id_approx - id).square().mean()#/id_approx.square().mean()).mean()  #((id_approx - id).square()/x.square().mean()).mean()#\n",
    "\n",
    "criterion = relative_inv_MSE\n",
    "lr = 1e-2# learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(matrix_dimension**2).to(device)\n",
    "\n",
    "    #num_batches = len(train_data) // bptt\n",
    "    for i in range(k):\n",
    "        #Currently just trying to overfit it on one matrix \n",
    "        data, targets = d,t #get_batch(matrix_parameters)\n",
    "        \n",
    "        #This is from the tutorial \n",
    "        #batch_size = data.size(0) \n",
    "        #if batch_size != bptt:  # only on last batch\n",
    "        #    src_mask = src_mask[:batch_size, :batch_size]\n",
    "        \n",
    "        output = model(data, src_mask, targets, tgt_mask)\n",
    "        #If we want to use (Xf(X)- 1) loss \n",
    "        loss = criterion(data.reshape(-1,matrix_dimension,matrix_dimension), output.reshape(-1,matrix_dimension,matrix_dimension))\n",
    "        #For trying other loss functions\n",
    "        #loss = criterion(output, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            #ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {i:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f}')\n",
    "            # print(f'| epoch {epoch:3d} | {i:5d} batches | '\n",
    "            #      f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "            #      f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "           \n",
    "#Not using this at the moment\n",
    "def evaluate(model: nn.Module, eval_parameters) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(matrix_dimension**2).to(device)\n",
    "    with torch.no_grad():\n",
    "        data, targets = get_batch(eval_parameters)\n",
    "            #batch_size = data.size(0)\n",
    "            #if batch_size != bptt:\n",
    "            #    src_mask = src_mask[:batch_size, :batch_size]\n",
    "        output = model(data, src_mask)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        total_loss += batch_size * criterion(output_flat, targets.reshape(-1,ntokens)).item()\n",
    "    return total_loss / (eval_parameters[\"N\"] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 1\n",
    "best_model = None\n",
    "eval_parameters = {\"N\": 100,\n",
    "                   \"d\": matrix_dimension}\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    #val_loss = evaluate(model, eval_parameters)\n",
    "    #val_ppl = math.exp(val_loss)\n",
    "    #elapsed = time.time() - epoch_start_time\n",
    "    #print('-' * 89)\n",
    "    #print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "    #      f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "    # print('-' * 89)\n",
    "\n",
    "    #if val_loss < best_val_loss:\n",
    "    #    best_val_loss = val_loss\n",
    "    #    best_model = copy.deepcopy(model)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce36fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(d,src_mask,t,tgt_mask)) #Just goes to some (or two) fixed values \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd47f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9f278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d61e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (pythonProject1)",
   "language": "python",
   "name": "pycharm-8a7ee7e4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
