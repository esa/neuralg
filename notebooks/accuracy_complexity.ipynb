{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append main folder\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np \n",
    "import torch\n",
    "from dotmap import DotMap\n",
    "from neuralg.utils.count_parameters import count_parameters\n",
    "from neuralg.models.nerf import EigNERF\n",
    "from neuralg.models.siren import EigSiren\n",
    "from neuralg.training.train_model import train_model\n",
    "from neuralg.training.save_run import save_run\n",
    "from neuralg.utils.set_log_level import set_log_level\n",
    "\n",
    "d = 5 # \n",
    "batch_size = 64\n",
    "train_matrix_parameters = DotMap({\"N\":batch_size, \n",
    "                            \"operation\": \"eig\", \n",
    "                            \"d\": d, \n",
    "                            \"wigner\": True})\n",
    "\n",
    "run_params = DotMap({ \"epoch\": 1, # Number of epochs\n",
    "                           \"iterations\": 10000, # Batches per epoch\n",
    "                           \"lr\": 3e-4} )       # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def estimate_runtime(model,d):\n",
    "    model.eval()\n",
    "    N = 1000\n",
    "    matrices = torch.rand(N,1,1,d,d)\n",
    "    start_time = time.time()\n",
    "    for i in range(N):\n",
    "        model(matrices[i])\n",
    "    ms_per_matrix = (time.time()-start_time)\n",
    "    return ms_per_matrix \n",
    "def runtime_per_batch(model,d):\n",
    "    mean = 0\n",
    "    for i in range(10):\n",
    "        batch = torch.rand(100,1,d,d)\n",
    "        start_time = time.time()\n",
    "        model(batch)\n",
    "        ms_per_batch = 1000*(time.time()-start_time)\n",
    "        mean += ms_per_batch\n",
    "    return mean/10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralg.evaluation.evaluate_model import evaluate_model\n",
    "from neuralg.evaluation.compute_accuracy import compute_accuracy\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "file_paths_5 = ['/Users/toveagren/ESA/results/nerf/relunerf5.pk','/Users/toveagren/ESA/results/nerf/sigmnerf5.pk','/Users/toveagren/ESA/results/siren/siren5.pk']\n",
    "file_paths_10 = ['/Users/toveagren/ESA/results/nerf/relunerf10.pk','/Users/toveagren/ESA/results/siren/siren10.pk']\n",
    "results = DotMap()\n",
    "tols = {\"5\": 0.05 , \"10\": 0.1}\n",
    "for file_path in file_paths_5 + file_paths_10:\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open(file_path, 'rb')\n",
    "\n",
    "    # dump information to that file\n",
    "    data = pickle.load(file)\n",
    "    data.runtime = []\n",
    "    data.batch_runtime = []\n",
    "    test_parameters = deepcopy(train_matrix_parameters)\n",
    "    d =  data.models[0].net[-1].out_features\n",
    "    test_parameters[\"N\"] = 10000\n",
    "    test_parameters[\"d\"] = d\n",
    "    tol = tols[str(d)]\n",
    "    for i, model in enumerate(data.models):\n",
    "        errors = evaluate_model(model,test_parameters)\n",
    "        accuracy = compute_accuracy(tol,errors)\n",
    "        data.accuracy.append(accuracy)\n",
    "        data.runtime.append(estimate_runtime(model,d))\n",
    "        data.batch_runtime.append(runtime_per_batch(model,d))\n",
    "\n",
    "    results[file_path] = data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})\n",
    "\n",
    "\n",
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "spec = fig.add_gridspec(1, 2)\n",
    "fig.suptitle(\"Trainable parameters \".format(100*tol), fontsize = 30)\n",
    "ax = fig.add_subplot(spec[0, 0])\n",
    "for file_path in file_paths_5:\n",
    "    label = results[file_path].models[0].__class__.__name__\n",
    "    d =  results[file_path].models[0].net[-1].out_features\n",
    "    if label == \"EigNERF\":\n",
    "        activation = str(results[file_path].models[0].net[0].activation)\n",
    "        label = label + ', ' + activation\n",
    "    ax.scatter(results[file_path].no_parameters,results[file_path].accuracy, s = 100, marker='o',label = label)\n",
    "    ax.set_title(\"$ {} \\\\times {}$ Wigner matrices, tol = {}$\\%$\".format(d,d,tols[\"5\"]*100), fontsize = 18)\n",
    "    ax.set_xlabel(\"$\\#$ of parameters \", fontsize = 18)\n",
    "    ax.set_ylabel(\"Accuracy\", fontsize = 18)\n",
    "    ax.set_xscale('log')\n",
    "ax.legend(fontsize = 16);\n",
    "\n",
    "ax = fig.add_subplot(spec[0, 1])\n",
    "for file_path in file_paths_10:\n",
    "    label = results[file_path].models[0].__class__.__name__\n",
    "    d =  results[file_path].models[0].net[-1].out_features\n",
    "    if label == \"EigNERF\":\n",
    "        activation = str(results[file_path].models[0].net[0].activation)\n",
    "        label = label + ', ' + activation\n",
    "    ax.scatter(results[file_path].no_parameters,results[file_path].accuracy, s = 100, marker='o',label = label)\n",
    "    ax.set_title(\"$ {} \\\\times {}$ Wigner matrices, tol = {}$\\% $ \".format(d,d,tols[\"10\"]*100), fontsize = 18)\n",
    "    ax.set_xlabel(\"$\\#$ of parameters \", fontsize = 18)\n",
    "    ax.set_ylabel(\"Accuracy\", fontsize = 18)\n",
    "    ax.set_xscale('log')\n",
    "ax.legend(fontsize = 16);\n",
    "#plt.savefig(\"trainable_parameters.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "spec = fig.add_gridspec(1, 2)\n",
    "layers,neurons = np.arange(5,11,2), [25,50,100,200]\n",
    "# #,[data.models[0].model_type,data.models[0].net[0].activation]\n",
    "ax = fig.add_subplot(spec[0, 0])\n",
    "xgrid, ygrid = np.meshgrid(layers,neurons)\n",
    "acc5nerf = results[file_paths_5[0]].accuracy\n",
    "acc5siren = results[file_paths_5[2]].accuracy\n",
    "fig.suptitle(\"Network hyperparameters \\n Model: EigNERF, Activation: ReLU() \", fontsize = 25)\n",
    "\n",
    "surf = ax.contourf(xgrid,ygrid, torch.flatten(torch.tensor(acc5nerf)).reshape((3,4)).transpose(0,1), cmap = cm.coolwarm, vmin = 0, vmax = 1)\n",
    "ax.set_title(\"$ {} \\\\times {}$ Wigner matrices \".format(5,5), fontsize = 18)\n",
    "ax.set_xlabel(\"$\\#$ of hidden layers \", fontsize = 18)\n",
    "ax.set_ylabel(\"$\\#$ of neurons per layer \", fontsize = 18)\n",
    "ax.set_xticks(np.arange(5, 11, 2))\n",
    "ax.set_yticks([25,50,100,200])\n",
    "\n",
    "fig.colorbar(surf, aspect=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "acc10nerf = results[file_paths_10[0]].accuracy\n",
    "acc10siren = results[file_paths_5[1]].accuracy\n",
    "ax = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "surf = ax.contourf(xgrid,ygrid, torch.flatten(torch.tensor(acc10nerf)).reshape((3,4)).transpose(0,1), cmap=cm.coolwarm)\n",
    "ax.set_title(\"Accuracy to network hyperparameters \".format(100*tol), fontsize = 18)\n",
    "ax.set_title(\"$ {} \\\\times {}$ Wigner matrices \".format(10,10), fontsize = 18)\n",
    "ax.set_xlabel(\"$\\#$ of hidden layers \", fontsize = 18)\n",
    "ax.set_ylabel(\"$\\#$ of neurons per layer \", fontsize = 18)\n",
    "ax.set_xticks(layers)\n",
    "ax.set_yticks(neurons)\n",
    "plt.colorbar(surf, aspect=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"hyperparameters.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.suptitle(\"Runtime per single matrix\", fontsize = 30)\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf5.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "xdata, ydata = results[file_path].runtime,results[file_path].no_parameters\n",
    "ax.scatter(xdata, acc5nerf, c=acc5nerf, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "#ax.scatter(xdata,  acc5siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "ax.set_xlabel(\"Runtime per matrix [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.grid(visible=True)\n",
    "#ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(ydata):\n",
    "    txt = f\"({torch.flatten(torch.tensor(xgrid).t())[i]}, {torch.flatten(torch.tensor(ygrid).t())[i]}) \\n \" + str(txt)\n",
    "    ax.annotate(txt, (xdata[i] + 0.0015, acc5nerf[i]), fontsize = 20)\n",
    "\n",
    "print(xdata)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf10.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "xdata, ydata = results[file_path].runtime,results[file_path].no_parameters\n",
    "ax.scatter(xdata, acc10nerf, c=acc5nerf, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "#ax.scatter(xdata,  acc10siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "ax.set_xlabel(\"Runtime per matrix [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.grid(visible=True)\n",
    "#ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(ydata):\n",
    "    txt = f\"({torch.flatten(torch.tensor(xgrid).t())[i]}, {torch.flatten(torch.tensor(ygrid).t())[i]}) \\n \" + str(txt)\n",
    "    ax.annotate(txt, (xdata[i] + 0.0015, acc10nerf[i]), fontsize = 20)\n",
    "#print(acc5)\n",
    "#plt.savefig(\"../runtime_per_matrix_nerf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.suptitle(\"Runtime per single matrix\", fontsize = 30)\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "file_path = \"/Users/toveagren/ESA/results/siren/siren5.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "xdata, ydata = results[file_path].runtime,results[file_path].no_parameters\n",
    "#ax.scatter(xdata, acc5nerf, c=acc5nerf, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "ax.scatter(xdata,  acc5siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "ax.set_xlabel(\"Runtime per matrix [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.grid(visible=True)\n",
    "#ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(ydata):\n",
    "    txt = f\"({torch.flatten(torch.tensor(xgrid).t())[i]}, {torch.flatten(torch.tensor(ygrid).t())[i]}) \\n \" + str(txt)\n",
    "    ax.annotate(txt, (xdata[i] + 0.005, acc5siren[i]-0.03), fontsize = 20)\n",
    "\n",
    "#print(acc5)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "file_path = \"/Users/toveagren/ESA/results/siren/siren10.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "xdata, ydata = results[file_path].runtime,results[file_path].no_parameters\n",
    "#ax.scatter(xdata, acc10nerf, c=acc5nerf, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "ax.scatter(xdata,  acc10siren, c=acc10siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "ax.set_xlabel(\"Runtime per matrix [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.grid(visible=True)\n",
    "#ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(ydata):\n",
    "    layers, neurons= torch.flatten(torch.tensor(xgrid).t())[i], torch.flatten(torch.tensor(ygrid).t())[i]\n",
    "    txt = f\"({layers}, {neurons}) \\n \" + str(txt)\n",
    "    if neurons > 25:\n",
    "        ax.annotate(txt, (xdata[i] + 0.005, acc10siren[i] -0.01), fontsize = 20)\n",
    "#print(acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = [16,16]\n",
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.suptitle(\"Runtime per batch, batch size = 100\", fontsize = 30)\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf5.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "x, y = results[file_path].batch_runtime, results[file_path].no_parameters\n",
    "ax.scatter(x, acc5nerf, c=acc5nerf, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "#ax.scatter(xdata,  acc5siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "ax.set_xlabel(\"Mean runtime per batch [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.grid(visible=True)\n",
    "#ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(y):\n",
    "    layers, neurons= torch.flatten(torch.tensor(xgrid).t())[i], torch.flatten(torch.tensor(ygrid).t())[i]\n",
    "    txt = f\"({layers}, {neurons}) \\n \" + str(txt)\n",
    "    if neurons > 50:\n",
    "        ax.annotate(txt, (x[i] + 0.02, acc5nerf[i]-0.01), fontsize = 20)\n",
    "#print(acc5)\n",
    "\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf10.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "xdata, ydata = results[file_path].batch_runtime,results[file_path].no_parameters\n",
    "ax.scatter(xdata, acc10nerf, c=acc10nerf, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "#ax.scatter(xdata,  acc10siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "ax.set_xlabel(\"Mean runtime per batch [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.grid(visible=True)\n",
    "#ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(ydata):\n",
    "    layers, neurons= torch.flatten(torch.tensor(xgrid).t())[i], torch.flatten(torch.tensor(ygrid).t())[i]\n",
    "    txt = f\"({layers}, {neurons}) \\n \" + str(txt)\n",
    "    if neurons > 50:\n",
    "        ax.annotate(txt, (xdata[i] + 0.03, acc10nerf[i] -0.01), fontsize = 20)\n",
    "print(acc5nerf)\n",
    "plt.savefig(\"../runtime_batch.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, matrices $A \\in \\mathbf{R}^{5\\times 5}$  will be refered to as small, while $B \\in \\mathbf{R}^{10\\times 10}$ are refered to as large.\n",
    "### Models\n",
    "Two different architectures are studied in this experiments. They are both densely connected nets. \n",
    "#### nerf\n",
    "For the nerf-model types, skips are made every other layer. \n",
    "#### siren \n",
    "The siren models have a hyperparameter $\\omega_0$. In this experiment, we set $\\omega_0$ = 1 (maybe tweek this a little for the larger mdeo)\n",
    "\n",
    "### Results\n",
    "#### Trainable parameters\n",
    "In \\cref{fig}, the\n",
    "#### Hyperparameters\n",
    "Varying the depth and width of the network evidently impacts prediction performance. \n",
    "\n",
    "#### Computational cost\n",
    "#### Per single matrix  \n",
    "The runtime for inference on one single matrix is approximated by taking the mean out of 10000 model evaluation runtimes on a random matrix. \n",
    "#### Per batch \n",
    "We also investigate if there are any differences in runtime results when predicting on batches of matrices. \n",
    "### Conclusions\n",
    "The resulting qualitative trends are mostly ?coherent? for small and large matrices. \n",
    "\n",
    "For small matrices, performance of the two different architectures (nerf and siren) are comparable in terms of accuracy per trainable parameter, the nerf-type model having a slight edge. This does not apply to the larger matrices, as even the most parameter rich siren models fail to provide accurate predictions. One should take into consideration that no attention was paid to the hyperparameter $\\omega_0$, thus additional performance improvements could be possible if optimized. \n",
    "\n",
    "Using relu activation appears more suitable than sigmoid in this application.\n",
    "\n",
    "In this particular experimental set-up, Fig[insert reference] implies that model performance depends largely on the width of the network, defined as number of neurons per hidden layer, rather than on depth, i.e. number of hidden layers. This implies that increasing performance (Although the training is not very extensive....)\n",
    "\n",
    "When considering accuracy alone, the EigNERF with 9 hidden layers and 200 neurons per layer proved superior for both small and large matrices, with an accuracy of 0.97 ($5\\%$ tolerance) on small matrices and 0.72 ($10\\%$ tolerance)  on larger matrices. This is indeed the most parameter-rich model, and Fig [] confirms the increase in computational cost that is commonly associated with larger models. In particular, increasing the depth of the network has a large impact on runtime. Thus, it is also of interest to evaluate accuracy and run time trade-off. For example, the EigNERF with 5 layers and 200 neurons achieved 0.91 accuracy, (6% decrease) but with a single matrix runtime of 0.24 ms (compared to 0.38ms for the largest model) (a 37% decrease). Introducing an efficiency index as $\\frac{\\text{Accuracy}}{\\text{Runtime per matrix}}$, \n",
    "\n",
    "A preliminary conclusion is that an efficient model benefits from \n",
    "\n",
    "0.2451319694519043, 0.23487305641174316, 0.23038983345031738, 0.24523472785949707, 0.2980022430419922, 0.2886011600494385, 0.29433488845825195, 0.3149130344390869, 0.34850406646728516, 0.35026001930236816, 0.3589670658111572, 0.3855729103088379\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.suptitle(\"Model efficiency index\", fontsize = 30)\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf5.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "efficiency = torch.tensor(results[file_path].accuracy)/torch.tensor(results[file_path].runtime)\n",
    "print(efficiency)\n",
    "\n",
    "efficiency, indices = torch.sort(efficiency, stable=True)\n",
    "p = torch.gather(torch.tensor(results[file_path].no_parameters),dim = 0, index=indices)\n",
    "xgrid_f = torch.gather(torch.flatten(torch.tensor(xgrid).t()),dim = 0, index=indices)\n",
    "ygrid_f =  torch.gather(torch.flatten(torch.tensor(ygrid).t()),dim = 0, index=indices)\n",
    "\n",
    "ax.scatter(np.arange(1,13,1), efficiency, c= efficiency, s = 200, cmap=cm.rainbow)# , label = label);\n",
    "#ax.scatter(xdata,  acc5siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "#ax.set_xlabel(\"Mean runtime per batch [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy/runtime\", fontsize = 20)\n",
    "ax.grid(visible=True)\n",
    "ax.set_xticks(np.arange(12,0,-1))\n",
    "for i, txt in enumerate(p):\n",
    "    layers, neurons= xgrid_f[i], ygrid_f[i]\n",
    "    txt = f\"({layers}, {neurons}) \\n \" + str(txt.item())\n",
    "#     if neurons > 50:\n",
    "    ax.annotate(txt, (i +1.1, efficiency[i]), fontsize = 20)\n",
    "# #print(acc5)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf10.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "efficiency = torch.tensor(results[file_path].accuracy)/torch.tensor(results[file_path].runtime)\n",
    "print(efficiency)\n",
    "\n",
    "efficiency, indices = torch.sort(efficiency, stable=True)\n",
    "p = torch.gather(torch.tensor(results[file_path].no_parameters),dim = 0, index=indices)\n",
    "xgrid_f = torch.gather(torch.flatten(torch.tensor(xgrid).t()),dim = 0, index=indices)\n",
    "ygrid_f =  torch.gather(torch.flatten(torch.tensor(ygrid).t()),dim = 0, index=indices)\n",
    "\n",
    "ax.scatter(np.arange(1,13,1), efficiency, c= efficiency, s = 200, cmap=cm.rainbow)# , label = label);\n",
    "#ax.scatter(xdata,  acc5siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "#ax.set_xlabel(\"Mean runtime per batch [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy/runtime\", fontsize = 20)\n",
    "ax.set_xticks(np.arange(12,0,-1))\n",
    "ax.grid(visible= True)\n",
    "for i, txt in enumerate(p):\n",
    "    layers, neurons= xgrid_f[i], ygrid_f[i]\n",
    "    txt = f\"({layers}, {neurons}) \\n \" + str(txt.item())\n",
    "#     if neurons > 50:\n",
    "    ax.annotate(txt, (i +1.1, efficiency[i]), fontsize = 20)\n",
    "# #print(acc5)\n",
    "\n",
    "#plt.savefig(\"../modelefficiency_nerf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(facecolor= 'white')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.suptitle(\"Model efficiency index\", fontsize = 30)\n",
    "ax = fig.add_subplot()\n",
    "file_path = \"/Users/toveagren/ESA/results/nerf/relunerf10.pk\"\n",
    "label = results[file_path].models[0].__class__.__name__\n",
    "d =  results[file_path].models[0].net[-1].out_features\n",
    "if label == \"EigNERF\":\n",
    "    activation = str(results[file_path].models[0].net[0].activation)\n",
    "    label = label + ', ' + activation\n",
    "efficiency = torch.tensor(results[file_path].accuracy)/torch.tensor(results[file_path].runtime)\n",
    "print(efficiency)\n",
    "\n",
    "efficiency, indices = torch.sort(efficiency, stable=True)\n",
    "p = torch.gather(torch.tensor(results[file_path].no_parameters),dim = 0, index=indices)\n",
    "xgrid_f = torch.gather(torch.flatten(torch.tensor(xgrid).t()),dim = 0, index=indices)\n",
    "ygrid_f =  torch.gather(torch.flatten(torch.tensor(ygrid).t()),dim = 0, index=indices)\n",
    "\n",
    "ax.scatter(np.arange(12,0,-1), efficiency, c= efficiency, s = 200, cmap=cm.coolwarm)# , label = label);\n",
    "#ax.scatter(xdata,  acc5siren, c=acc5siren, s = 200, cmap=cm.cool)# , label = label);\n",
    "ax.set_title(f\"$ {d} \\\\times {d}$ Wigner matrices. Model: \" + label , fontsize = 18)\n",
    "#ax.set_xlabel(\"Mean runtime per batch [ms]\", fontsize = 20)\n",
    "ax.set_ylabel(\"Accuracy/runtime\", fontsize = 20)\n",
    "ax.legend(fontsize = 16);\n",
    "for i, txt in enumerate(p):\n",
    "    layers, neurons= xgrid_f[i], ygrid_f[i]\n",
    "    txt = f\"({layers}, {neurons}) \\n \" + str(txt.item())\n",
    "#     if neurons > 50:\n",
    "    ax.annotate(txt, (i +1.1, efficiency[-(i+1)]), fontsize = 20)\n",
    "# #print(acc5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(facecolor= 'white')\n",
    "# fig.patch.set_facecolor('white')\n",
    "# fig.suptitle(\"Accuracy to runtime\", fontsize = 25)\n",
    "# ax = fig.add_subplot(projection = '3d')\n",
    "# file_path = \"/Users/toveagren/ESA/results/nerf/relunerf5.pk\"\n",
    "# label = results[file_path].models[0].__class__.__name__\n",
    "# d =  results[file_path].models[0].net[-1].out_features\n",
    "# if label == \"EigNERF\":\n",
    "#     activation = str(results[file_path].models[0].net[0].activation)\n",
    "#     label = label + ', ' + activation\n",
    "# xdata, ydata = results[file_path].runtime,results[file_path].no_parameters\n",
    "# print(xdata)\n",
    "# ax.scatter3D(xdata, ydata, acc5nerf, c=acc5nerf, s = 200, cmap=cm.coolwarm, label = label);\n",
    "\n",
    "# #ax.set_title(\"$ {} \\\\times {}$ Wigner matrices, tol = {}$\\%$\".format(d,d,), fontsize = 18)\n",
    "# ax.set_xlabel(\"Runtime [ms]\", fontsize = 18)\n",
    "# ax.set_ylabel(\"$\\#$ of parameters\", fontsize = 18)\n",
    "# ax.legend(fontsize = 16);\n",
    "\n",
    "# import torch\n",
    "# from loguru import logger\n",
    "\n",
    "# training_runs = DotMap({\"models\": [], \"no_parameters\": [],  \"loss_logs\": [], \"accuracy\": []})\n",
    "\n",
    "# for hidden_layers in torch.arange(4,11,2):\n",
    "#     run = DotMap()\n",
    "#     skip = torch.arange(2,hidden_layers-1,2)\n",
    "#     for n_neurons in [25,50,100,200]: \n",
    "#         #model = EigNERF(d,d**2,n_neurons= n_neurons,skip = skip, hidden_layers=hidden_layers)\n",
    "#         model = EigSiren(d,hidden_features = n_neurons, hidden_layers=hidden_layers)\n",
    "#         no_parameters = count_parameters(model)\n",
    "#         logger.trace(f'Training model with {hidden_layers} hidden layers, {n_neurons} neurons, skipping layer(s) {skip}')\n",
    "#         training_run = train_model(model,train_matrix_parameters,run_parameters= run_params)\n",
    "#         training_runs.no_parameters.append(count_parameters(model))\n",
    "#         training_runs.models.append(training_run.model)\n",
    "#         training_runs.loss_logs.append(training_run.results)\n",
    "# save_run(training_runs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33b13c0f5861550def7c5fd31dfce4700e1b96089b8cc03c6412b21d90f85adf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('freshpy3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
